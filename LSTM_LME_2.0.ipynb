{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "723dfe25-3c26-47e4-9748-2cce2d6352e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "import ta\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72476e39-f266-4e83-bcbc-2ba420fa6d2a",
   "metadata": {},
   "source": [
    "### 1. Read and visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d920b88-8bd0-43d1-98ad-8d73a739cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['ali', 'copper', 'lead', 'nickel', 'zinc']\n",
    "dataset_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4765c362-423b-4a6c-a5f4-b054c8681637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>PX_HIGH</th>\n",
       "      <th>PX_LOW</th>\n",
       "      <th>PX_OPEN</th>\n",
       "      <th>PX_LAST</th>\n",
       "      <th>PX_VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>1</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  day_of_week  PX_HIGH  PX_LOW  PX_OPEN  PX_LAST  PX_VOLUME\n",
       "3788 2018-12-25            1   1883.0  1883.0   1883.0   1883.0        NaN\n",
       "3792 2019-01-01            1   1853.0  1853.0   1853.0   1853.0        NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file = \"./Data/{}.csv\".format(datasets[dataset_idx])\n",
    "df = pd.read_csv(dataset_file, index_col=0)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df['month'] = df['date'].dt.month.astype(int)\n",
    "df['day_of_month'] = df['date'].dt.day.astype(int)\n",
    "\n",
    "# day_of_week=0 corresponds to Monday\n",
    "df['day_of_week'] = df['date'].dt.dayofweek.astype(int)\n",
    "# df['hour_of_day'] = df['date'].dt.hour.astype(int)\n",
    "\n",
    "selected_columns = ['date', 'day_of_week', 'PX_HIGH', 'PX_LOW', 'PX_OPEN', 'PX_LAST', 'PX_VOLUME']\n",
    "df = df[selected_columns]\n",
    "\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf36008-ba23-4f35-9f74-db99fb029ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>PX_HIGH</th>\n",
       "      <th>PX_LOW</th>\n",
       "      <th>PX_OPEN</th>\n",
       "      <th>PX_LAST</th>\n",
       "      <th>PX_VOLUME</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-02</th>\n",
       "      <td>4</td>\n",
       "      <td>1623.5</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>1236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-06</th>\n",
       "      <td>1</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-07</th>\n",
       "      <td>2</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>3</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>870.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            day_of_week  PX_HIGH  PX_LOW  PX_OPEN  PX_LAST  PX_VOLUME\n",
       "date                                                                 \n",
       "2004-01-02            4   1623.5  1600.0   1604.0   1619.0     1236.0\n",
       "2004-01-05            0   1623.0  1608.0   1621.0   1615.0      991.0\n",
       "2004-01-06            1   1623.0  1603.0   1618.0   1608.0      718.0\n",
       "2004-01-07            2   1609.0  1600.0   1606.0   1600.0      366.0\n",
       "2004-01-08            3   1623.0  1594.0   1603.0   1620.0      870.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "\n",
    "df.set_index('date', drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c02f96-ade0-4a57-a65e-17856b9bfa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5444 entries, 2004-01-02 to 2025-07-18\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   day_of_week  5444 non-null   int64  \n",
      " 1   PX_HIGH      5444 non-null   float64\n",
      " 2   PX_LOW       5444 non-null   float64\n",
      " 3   PX_OPEN      5444 non-null   float64\n",
      " 4   PX_LAST      5444 non-null   float64\n",
      " 5   PX_VOLUME    5444 non-null   float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 297.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b542699-dd9a-4f28-ad7f-540de762d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all ta features\n",
    "# df = add_all_ta_features(df, open=\"PX_OPEN\", high=\"PX_HIGH\", low=\"PX_LOW\", close=\"PX_LAST\", volume=\"PX_VOLUME\")\n",
    "# df.columns\n",
    "\n",
    "df['SMA20'] = ta.trend.sma_indicator(df.PX_LAST, window=20, fillna=False)\n",
    "df['SMA50'] = ta.trend.sma_indicator(df.PX_LAST, window=50, fillna=False)\n",
    "\n",
    "df['EMA20'] = ta.trend.ema_indicator(df.PX_LAST, window=20, fillna=False)\n",
    "df['EMA50'] = ta.trend.ema_indicator(df.PX_LAST, window=50, fillna=False)\n",
    "\n",
    "df['ADX'] = ta.trend.adx(df['PX_HIGH'], df['PX_LOW'], df['PX_LAST'], window=14, fillna=False)\n",
    "\n",
    "df['MACD'] = ta.trend.macd(df['PX_HIGH'], window_slow=26, window_fast=12, fillna=False)\n",
    "df['MACD_SIG'] = ta.trend.macd_signal(df['PX_HIGH'], window_slow=26, window_fast=12, window_sign=9, fillna=False)\n",
    "\n",
    "df['RSI'] = ta.momentum.rsi(df['PX_HIGH'], window=14, fillna=False)\n",
    "\n",
    "df['upper'] = ta.volatility.bollinger_hband(df['PX_HIGH'], window=20, window_dev=2, fillna=False)\n",
    "df['mid'] = ta.volatility.bollinger_mavg(df['PX_HIGH'], window=20, fillna=False)\n",
    "df['lower'] = ta.volatility.bollinger_lband(df['PX_HIGH'], window=20, window_dev=2, fillna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48eccf91-584c-46a4-bac6-60e4e7af706c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>PX_HIGH</th>\n",
       "      <th>PX_LOW</th>\n",
       "      <th>PX_OPEN</th>\n",
       "      <th>PX_LAST</th>\n",
       "      <th>PX_VOLUME</th>\n",
       "      <th>SMA20</th>\n",
       "      <th>SMA50</th>\n",
       "      <th>EMA20</th>\n",
       "      <th>EMA50</th>\n",
       "      <th>ADX</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_SIG</th>\n",
       "      <th>RSI</th>\n",
       "      <th>upper</th>\n",
       "      <th>mid</th>\n",
       "      <th>lower</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-03-11</th>\n",
       "      <td>3</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>1667.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>1707.625</td>\n",
       "      <td>1666.95</td>\n",
       "      <td>1688.307137</td>\n",
       "      <td>1673.987500</td>\n",
       "      <td>35.887244</td>\n",
       "      <td>-2.583332</td>\n",
       "      <td>7.677975</td>\n",
       "      <td>47.792100</td>\n",
       "      <td>1785.940857</td>\n",
       "      <td>1720.425</td>\n",
       "      <td>1654.909143</td>\n",
       "      <td>2004-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-12</th>\n",
       "      <td>4</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>1663.0</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>1664.5</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>1704.850</td>\n",
       "      <td>1667.86</td>\n",
       "      <td>1686.039790</td>\n",
       "      <td>1673.615441</td>\n",
       "      <td>33.664713</td>\n",
       "      <td>-2.777353</td>\n",
       "      <td>5.586910</td>\n",
       "      <td>48.080923</td>\n",
       "      <td>1785.431428</td>\n",
       "      <td>1718.725</td>\n",
       "      <td>1652.018572</td>\n",
       "      <td>2004-03-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-15</th>\n",
       "      <td>0</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>1662.0</td>\n",
       "      <td>1671.0</td>\n",
       "      <td>1673.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>1702.175</td>\n",
       "      <td>1669.02</td>\n",
       "      <td>1684.797905</td>\n",
       "      <td>1673.591306</td>\n",
       "      <td>31.553195</td>\n",
       "      <td>-4.094295</td>\n",
       "      <td>3.650669</td>\n",
       "      <td>44.136615</td>\n",
       "      <td>1784.832383</td>\n",
       "      <td>1715.925</td>\n",
       "      <td>1647.017617</td>\n",
       "      <td>2004-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-16</th>\n",
       "      <td>1</td>\n",
       "      <td>1695.0</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1699.575</td>\n",
       "      <td>1670.70</td>\n",
       "      <td>1685.483819</td>\n",
       "      <td>1674.313216</td>\n",
       "      <td>30.383330</td>\n",
       "      <td>-3.563759</td>\n",
       "      <td>2.207783</td>\n",
       "      <td>49.758799</td>\n",
       "      <td>1781.555225</td>\n",
       "      <td>1713.425</td>\n",
       "      <td>1645.294775</td>\n",
       "      <td>2004-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-03-17</th>\n",
       "      <td>2</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1696.000</td>\n",
       "      <td>1672.06</td>\n",
       "      <td>1683.818694</td>\n",
       "      <td>1674.065639</td>\n",
       "      <td>28.791736</td>\n",
       "      <td>-2.947939</td>\n",
       "      <td>1.176639</td>\n",
       "      <td>50.325524</td>\n",
       "      <td>1771.786927</td>\n",
       "      <td>1709.525</td>\n",
       "      <td>1647.263073</td>\n",
       "      <td>2004-03-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            day_of_week  PX_HIGH  PX_LOW  PX_OPEN  PX_LAST  PX_VOLUME  \\\n",
       "date                                                                    \n",
       "2004-03-11            3   1690.0  1660.0   1667.0   1689.0     1515.0   \n",
       "2004-03-12            4   1691.0  1663.0   1691.0   1664.5     1152.0   \n",
       "2004-03-15            0   1676.0  1662.0   1671.0   1673.0      636.0   \n",
       "2004-03-16            1   1695.0  1675.0   1683.0   1692.0     1029.0   \n",
       "2004-03-17            2   1697.0  1665.0   1688.0   1668.0      850.0   \n",
       "\n",
       "               SMA20    SMA50        EMA20        EMA50        ADX      MACD  \\\n",
       "date                                                                           \n",
       "2004-03-11  1707.625  1666.95  1688.307137  1673.987500  35.887244 -2.583332   \n",
       "2004-03-12  1704.850  1667.86  1686.039790  1673.615441  33.664713 -2.777353   \n",
       "2004-03-15  1702.175  1669.02  1684.797905  1673.591306  31.553195 -4.094295   \n",
       "2004-03-16  1699.575  1670.70  1685.483819  1674.313216  30.383330 -3.563759   \n",
       "2004-03-17  1696.000  1672.06  1683.818694  1674.065639  28.791736 -2.947939   \n",
       "\n",
       "            MACD_SIG        RSI        upper       mid        lower       date  \n",
       "date                                                                            \n",
       "2004-03-11  7.677975  47.792100  1785.940857  1720.425  1654.909143 2004-03-11  \n",
       "2004-03-12  5.586910  48.080923  1785.431428  1718.725  1652.018572 2004-03-12  \n",
       "2004-03-15  3.650669  44.136615  1784.832383  1715.925  1647.017617 2004-03-15  \n",
       "2004-03-16  2.207783  49.758799  1781.555225  1713.425  1645.294775 2004-03-16  \n",
       "2004-03-17  1.176639  50.325524  1771.786927  1709.525  1647.263073 2004-03-17  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df['date'] = df.index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e12f3fa6-9dee-4f83-9274-9bfb930dbf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_8.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_length = len(df)\n",
    "# plot_length = 150\n",
    "plot_df = df.copy(deep=True).iloc[:plot_length]\n",
    "plot_df['weekday'] = plot_df['date'].dt.day_name()\n",
    "\n",
    "fig = px.line(plot_df,\n",
    "              x=\"date\",\n",
    "              y=\"PX_LAST\",\n",
    "              # color=\"weekday\",\n",
    "              title=\"{} Price Over Time\".format(datasets[dataset_idx]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22568e5-2b5a-4ddf-9166-0521b0e9c408",
   "metadata": {},
   "source": [
    "### 2. Data processing for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d74fbc60-9d0c-483d-839a-7837f1120590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_window(data, feature_length, output_length, stride=1):\n",
    "    X_list, y_list = [], []\n",
    "    for i in range(len(data)):\n",
    "      if (i + feature_length + output_length) < len(data):\n",
    "        X_list.append(data.iloc[i:i+feature_length:stride, 1:].values)\n",
    "        y_list.append(data.iloc[i+feature_length:i+feature_length+output_length:stride, 0])\n",
    "    return np.array(X_list), np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e77616-5084-45b0-84fe-e23add71d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3776, 30, 11) (3776, 10) (1579, 30, 11) (1579, 10)\n"
     ]
    }
   ],
   "source": [
    "train_split = 0.7\n",
    "n_train = int(train_split * len(df))\n",
    "n_test = len(df) - n_train\n",
    "\n",
    "feature_array = df.drop(columns=['day_of_week', 'PX_HIGH', 'PX_LOW', 'PX_OPEN', 'PX_VOLUME', 'date']).values\n",
    "target_array = df.PX_LAST.values\n",
    "\n",
    "# Fit Scaler only on Training features\n",
    "feature_scaler = MinMaxScaler()\n",
    "feature_scaler.fit(feature_array[:n_train])\n",
    "# Fit Scaler only on Training target values\n",
    "target_scaler = MinMaxScaler()\n",
    "target_scaler.fit(target_array[:n_train].reshape(-1, 1))\n",
    "\n",
    "# Transfom on both Training and Test data\n",
    "scaled_array = pd.DataFrame(feature_scaler.transform(feature_array),\n",
    "                            columns=df.drop(columns=['day_of_week', 'PX_HIGH', 'PX_LOW', 'PX_OPEN', 'PX_VOLUME', 'date']).columns)\n",
    "\n",
    "feature_length = 30\n",
    "output_length = 10\n",
    "X, y = create_sliding_window(scaled_array, feature_length, output_length)\n",
    "\n",
    "X_train = X[:n_train]\n",
    "y_train = y[:n_train]\n",
    "\n",
    "X_test = X[n_train:]\n",
    "y_test = y[n_train:]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8f2dae-b00d-475b-84a6-dc2aa6db4c4c",
   "metadata": {},
   "source": [
    "### 3. LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f004d9-e4ef-4f27-a602-02a6b068c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features, output_length, batch_size):\n",
    "\n",
    "        super(BayesianLSTM, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size # user-defined\n",
    "\n",
    "        self.hidden_size_1 = 128 # number of encoder cells (from paper)\n",
    "        self.hidden_size_2 = 32 # number of decoder cells (from paper)\n",
    "        self.stacked_layers = 2 # number of (stacked) LSTM layers for each stage\n",
    "        self.dropout_probability = 0.5 # arbitrary value (the paper suggests that performance is generally stable across all ranges)\n",
    "\n",
    "        self.lstm1 = nn.LSTM(n_features,\n",
    "                             self.hidden_size_1,\n",
    "                             num_layers=self.stacked_layers,\n",
    "                             batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(self.hidden_size_1,\n",
    "                             self.hidden_size_2,\n",
    "                             num_layers=self.stacked_layers,\n",
    "                             batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(self.hidden_size_2, output_length)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        hidden = self.init_hidden1(batch_size)\n",
    "        output, _ = self.lstm1(x, hidden)\n",
    "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
    "        state = self.init_hidden2(batch_size)\n",
    "        output, state = self.lstm2(output, state)\n",
    "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
    "        # Important when lstm num_layers > 1\n",
    "        output = output[:, -1, :] # take the last decoder cell's outputs\n",
    "        y_pred = self.fc(output)\n",
    "        return y_pred\n",
    "\n",
    "    def init_hidden1(self, batch_size):\n",
    "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
    "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
    "        return hidden_state, cell_state\n",
    "\n",
    "    def init_hidden2(self, batch_size):\n",
    "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
    "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
    "        return hidden_state, cell_state\n",
    "\n",
    "    def loss(self, pred, truth):\n",
    "        return self.loss_fn(pred, truth)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self(torch.tensor(X, dtype=torch.float32)).view(-1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b614a396-ce45-4fff-8ba5-11481c08efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = scaled_array.shape[-1] - 1\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 200\n",
    "learning_rate = 1e-3\n",
    "\n",
    "bayesian_lstm = BayesianLSTM(n_features=n_features,\n",
    "                             output_length=output_length,\n",
    "                             batch_size = batch_size)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(bayesian_lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "666cd995-94d1-4759-9327-48e3310f81f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 loss:  0.004277965519577265\n",
      "epoch 20 loss:  0.0019582558888942003\n",
      "epoch 30 loss:  0.0011376111069694161\n",
      "epoch 40 loss:  0.0011362405493855476\n",
      "epoch 50 loss:  0.0009438177803531289\n",
      "epoch 60 loss:  0.001137839863076806\n",
      "epoch 70 loss:  0.0008624814217910171\n",
      "epoch 80 loss:  0.0009247410926036537\n",
      "epoch 90 loss:  0.0004696151299867779\n",
      "epoch 100 loss:  0.0007684663287363946\n",
      "epoch 110 loss:  0.0005354161839932203\n",
      "epoch 120 loss:  0.000553412304725498\n",
      "epoch 130 loss:  0.00048451745533384383\n",
      "epoch 140 loss:  0.000516432395670563\n",
      "epoch 150 loss:  0.0010227393358945847\n",
      "epoch 160 loss:  0.0006863424787297845\n",
      "epoch 170 loss:  0.0009636234608478844\n",
      "epoch 180 loss:  0.0009592299466021359\n",
      "epoch 190 loss:  0.0006765298894606531\n",
      "epoch 200 loss:  0.0032008022535592318\n"
     ]
    }
   ],
   "source": [
    "bayesian_lstm.train()\n",
    "\n",
    "for e in range(1, n_epochs+1):\n",
    "    for b in range(0, len(X_train), batch_size):\n",
    "        features = X_train[b:b+batch_size,:,:]\n",
    "        target = y_train[b:b+batch_size].flatten()\n",
    "\n",
    "        X_batch = torch.tensor(features,dtype=torch.float32)\n",
    "        y_batch = torch.tensor(target,dtype=torch.float32)\n",
    "\n",
    "        output = bayesian_lstm(X_batch)\n",
    "        loss = criterion(output.view(-1), y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if e % 10 == 0:\n",
    "      print('epoch', e, 'loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6159cd5-cad8-4f41-803b-13cb94393ced",
   "metadata": {},
   "source": [
    "### 4. Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7c03a8-e758-4ebd-a4cd-e7248391abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(y):\n",
    "    return target_scaler.inverse_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44b20e3e-acb6-4a96-8081-546d8cefaf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = feature_length + output_length\n",
    "\n",
    "training_df = pd.DataFrame()\n",
    "training_df['date'] = df['date'].iloc[offset:n_train + offset:1]\n",
    "training_predictions = bayesian_lstm.predict(X_train)[::10]\n",
    "training_df['Close'] = inverse_transform(training_predictions)\n",
    "training_df['source'] = 'Training Prediction'\n",
    "\n",
    "training_truth_df = pd.DataFrame()\n",
    "training_truth_df['date'] = training_df['date']\n",
    "training_truth_df['Close'] = df['PX_LAST'].iloc[offset:n_train + offset:1]\n",
    "training_truth_df['source'] = 'True Values'\n",
    "\n",
    "testing_df = pd.DataFrame()\n",
    "testing_df['date'] = df['date'].iloc[n_train + offset::1]\n",
    "testing_predictions = bayesian_lstm.predict(X_test)[::10]\n",
    "testing_df['Close'] = inverse_transform(testing_predictions)\n",
    "testing_df['source'] = 'Test Prediction'\n",
    "\n",
    "testing_truth_df = pd.DataFrame()\n",
    "testing_truth_df['date'] = testing_df['date']\n",
    "testing_truth_df['Close'] = df['PX_LAST'].iloc[n_train + offset::1]\n",
    "testing_truth_df['source'] = 'True Values'\n",
    "\n",
    "evaluation = pd.concat([training_df,\n",
    "                        testing_df,\n",
    "                        training_truth_df,\n",
    "                        testing_truth_df\n",
    "                        ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c69f32f-2042-49f8-8ea5-d22c32a48567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_16.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.line(evaluation,\n",
    "                 x=\"date\",\n",
    "                 y=\"Close\",\n",
    "                 color=\"source\",\n",
    "                 title=\"{} Price Over Time\".format(datasets[dataset_idx]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4029283d-ebe5-4b6c-9118-061e35e0a150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Di.Sha\\AppData\\Local\\Temp\\ipykernel_7256\\648296752.py:8: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\Di.Sha\\AppData\\Local\\Temp\\ipykernel_7256\\648296752.py:11: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\Di.Sha\\AppData\\Local\\Temp\\ipykernel_7256\\648296752.py:12: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_experiments = 100\n",
    "\n",
    "test_uncertainty_df = pd.DataFrame()\n",
    "test_uncertainty_df['date'] = testing_df['date']\n",
    "\n",
    "for i in range(n_experiments):\n",
    "  experiment_predictions = bayesian_lstm.predict(X_test)[::10]\n",
    "  test_uncertainty_df['Close_{}'.format(i)] = inverse_transform(experiment_predictions)\n",
    "\n",
    "Close_df = test_uncertainty_df.filter(like='Close', axis=1)\n",
    "test_uncertainty_df['Close_mean'] = Close_df.mean(axis=1)\n",
    "test_uncertainty_df['Close_std'] = Close_df.std(axis=1)\n",
    "\n",
    "test_uncertainty_df = test_uncertainty_df[['date', 'Close_mean', 'Close_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9729c02c-28e0-4900-827f-4a652d3dc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_uncertainty_df['lower_bound'] = test_uncertainty_df['Close_mean'] - 3*test_uncertainty_df['Close_std']\n",
    "test_uncertainty_df['upper_bound'] = test_uncertainty_df['Close_mean'] + 3*test_uncertainty_df['Close_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8709dcbb-21d2-4e4b-8a7a-e93fa1055763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_19.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_uncertainty_plot_df = test_uncertainty_df.copy(deep=True)\n",
    "test_uncertainty_plot_df = test_uncertainty_plot_df\n",
    "truth_uncertainty_plot_df = testing_truth_df.copy(deep=True)\n",
    "truth_uncertainty_plot_df = truth_uncertainty_plot_df\n",
    "\n",
    "upper_trace = go.Scatter(\n",
    "    x=test_uncertainty_plot_df['date'],\n",
    "    y=test_uncertainty_plot_df['upper_bound'],\n",
    "    mode='lines',\n",
    "    fill=None,\n",
    "    name='99% Upper Confidence Bound'\n",
    "    )\n",
    "lower_trace = go.Scatter(\n",
    "    x=test_uncertainty_plot_df['date'],\n",
    "    y=test_uncertainty_plot_df['lower_bound'],\n",
    "    mode='lines',\n",
    "    fill='tonexty',\n",
    "    fillcolor='rgba(255, 211, 0, 0.1)',\n",
    "    name='99% Lower Confidence Bound'\n",
    "    )\n",
    "real_trace = go.Scatter(\n",
    "    x=truth_uncertainty_plot_df['date'],\n",
    "    y=truth_uncertainty_plot_df['Close'],\n",
    "    mode='lines',\n",
    "    fill=None,\n",
    "    name='Real Values'\n",
    "    )\n",
    "\n",
    "data = [upper_trace, lower_trace, real_trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "fig.update_layout(title='Uncertainty Quantification for {} Price Test Data'.format(datasets[dataset_idx]),\n",
    "                   xaxis_title='Year',\n",
    "                   yaxis_title='Price (USD)')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73d14497-291a-4e83-93d6-35bffc0420bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of points contained within 99% confidence interval: 0.6276124129195694\n"
     ]
    }
   ],
   "source": [
    "bounds_df = pd.DataFrame()\n",
    "\n",
    "# Using 99% confidence bounds\n",
    "bounds_df['lower_bound'] = test_uncertainty_plot_df['lower_bound']\n",
    "bounds_df['prediction'] = test_uncertainty_plot_df['Close_mean']\n",
    "bounds_df['real_value'] = truth_uncertainty_plot_df['Close']\n",
    "bounds_df['upper_bound'] = test_uncertainty_plot_df['upper_bound']\n",
    "\n",
    "bounds_df['contained'] = ((bounds_df['real_value'] >= bounds_df['lower_bound']) &\n",
    "                          (bounds_df['real_value'] <= bounds_df['upper_bound']))\n",
    "\n",
    "print(\"Proportion of points contained within 99% confidence interval:\",\n",
    "      bounds_df['contained'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
