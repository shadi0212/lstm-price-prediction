{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa8f7da4-7bd6-4ade-9d5a-8a8feb234ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5dc24457-76b7-4cb1-92e8-86c19c108793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-01-02</td>\n",
       "      <td>4</td>\n",
       "      <td>2349.0</td>\n",
       "      <td>2307.0</td>\n",
       "      <td>2307.0</td>\n",
       "      <td>2346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>2354.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>2376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>2345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-01-07</td>\n",
       "      <td>2</td>\n",
       "      <td>2360.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>2335.0</td>\n",
       "      <td>2329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-01-08</td>\n",
       "      <td>3</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>2324.0</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>2424.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  day_of_week    High     Low    Open   Close\n",
       "0 2004-01-02            4  2349.0  2307.0  2307.0  2346.0\n",
       "1 2004-01-05            0  2385.0  2354.0  2370.0  2376.0\n",
       "2 2004-01-06            1  2391.0  2320.0  2378.0  2345.0\n",
       "3 2004-01-07            2  2360.0  2310.0  2335.0  2329.0\n",
       "4 2004-01-08            3  2425.0  2324.0  2350.0  2424.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file = \"./Data/LME COPPER PRICE.xlsx\"\n",
    "df = pd.read_excel(dataset_file, sheet_name='Sheet1')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['month'] = df['Date'].dt.month.astype(int)\n",
    "df['day_of_month'] = df['Date'].dt.day.astype(int)\n",
    "\n",
    "# day_of_week=0 corresponds to Monday\n",
    "df['day_of_week'] = df['Date'].dt.dayofweek.astype(int)\n",
    "# df['hour_of_day'] = df['Date'].dt.hour.astype(int)\n",
    "\n",
    "selected_columns = ['Date', 'day_of_week', 'High', 'Low', 'Open', 'Close']\n",
    "df = df[selected_columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc17756-5247-4152-8556-30895ce2188b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-02</th>\n",
       "      <td>2004-01-02</td>\n",
       "      <td>4</td>\n",
       "      <td>2349.0</td>\n",
       "      <td>2307.0</td>\n",
       "      <td>2307.0</td>\n",
       "      <td>2346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-05</th>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>2354.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>2376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-06</th>\n",
       "      <td>2004-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>2345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-07</th>\n",
       "      <td>2004-01-07</td>\n",
       "      <td>2</td>\n",
       "      <td>2360.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>2335.0</td>\n",
       "      <td>2329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>2004-01-08</td>\n",
       "      <td>3</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>2324.0</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>2424.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  day_of_week    High     Low    Open   Close\n",
       "Date                                                              \n",
       "2004-01-02 2004-01-02            4  2349.0  2307.0  2307.0  2346.0\n",
       "2004-01-05 2004-01-05            0  2385.0  2354.0  2370.0  2376.0\n",
       "2004-01-06 2004-01-06            1  2391.0  2320.0  2378.0  2345.0\n",
       "2004-01-07 2004-01-07            2  2360.0  2310.0  2335.0  2329.0\n",
       "2004-01-08 2004-01-08            3  2425.0  2324.0  2350.0  2424.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('Date', inplace=True)\n",
    "df['date'] = df.index\n",
    "\n",
    "datetime_columns = ['date', 'day_of_week', 'High', 'Low', 'Open']\n",
    "target_column = 'Close'\n",
    "\n",
    "feature_columns = datetime_columns + ['Close']\n",
    "\n",
    "# For clarity in visualization and presentation,\n",
    "# only consider the first 150 hours of data.\n",
    "df = df[feature_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96a07033-77a9-4023-a904-13b1cd9bb7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_11.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_length = len(df)\n",
    "# plot_length = 150\n",
    "plot_df = df.copy(deep=True).iloc[:plot_length]\n",
    "plot_df['weekday'] = plot_df['date'].dt.day_name()\n",
    "\n",
    "fig = px.line(plot_df,\n",
    "              x=\"date\",\n",
    "              y=\"Close\",\n",
    "              # color=\"weekday\",\n",
    "              title=\"Copper Price Over Time\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e408e307-df96-47c5-bf5f-c35298ebd6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_window(data, sequence_length, stride=1):\n",
    "    X_list, y_list = [], []\n",
    "    for i in range(len(data)):\n",
    "      if (i + sequence_length) < len(data):\n",
    "        X_list.append(data.iloc[i:i+sequence_length:stride, :].values)\n",
    "        y_list.append(data.iloc[i+sequence_length, -1])\n",
    "    return np.array(X_list), np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce386b2e-a169-401b-8442-b1deebc74850",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.7\n",
    "n_train = int(train_split * len(df))\n",
    "n_test = len(df) - n_train\n",
    "\n",
    "features = ['day_of_week', 'High', 'Low', 'Open', 'Close']\n",
    "feature_array = df[features].values\n",
    "\n",
    "# Fit Scaler only on Training features\n",
    "feature_scaler = MinMaxScaler()\n",
    "feature_scaler.fit(feature_array[:n_train])\n",
    "# Fit Scaler only on Training target values\n",
    "target_scaler = MinMaxScaler()\n",
    "target_scaler.fit(feature_array[:n_train, -1].reshape(-1, 1))\n",
    "\n",
    "# Transfom on both Training and Test data\n",
    "scaled_array = pd.DataFrame(feature_scaler.transform(feature_array),\n",
    "                            columns=features)\n",
    "\n",
    "sequence_length = 10\n",
    "X, y = create_sliding_window(scaled_array,\n",
    "                             sequence_length)\n",
    "\n",
    "X_train = X[:n_train]\n",
    "y_train = y[:n_train]\n",
    "\n",
    "X_test = X[n_train:]\n",
    "y_test = y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a56b8400-65e4-4d6a-8585-69a5214d8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features, output_length, batch_size):\n",
    "\n",
    "        super(BayesianLSTM, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size # user-defined\n",
    "\n",
    "        self.hidden_size_1 = 128 # number of encoder cells (from paper)\n",
    "        self.hidden_size_2 = 32 # number of decoder cells (from paper)\n",
    "        self.stacked_layers = 2 # number of (stacked) LSTM layers for each stage\n",
    "        self.dropout_probability = 0.5 # arbitrary value (the paper suggests that performance is generally stable across all ranges)\n",
    "\n",
    "        self.lstm1 = nn.LSTM(n_features,\n",
    "                             self.hidden_size_1,\n",
    "                             num_layers=self.stacked_layers,\n",
    "                             batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(self.hidden_size_1,\n",
    "                             self.hidden_size_2,\n",
    "                             num_layers=self.stacked_layers,\n",
    "                             batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(self.hidden_size_2, output_length)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        hidden = self.init_hidden1(batch_size)\n",
    "        output, _ = self.lstm1(x, hidden)\n",
    "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
    "        state = self.init_hidden2(batch_size)\n",
    "        output, state = self.lstm2(output, state)\n",
    "        output = F.dropout(output, p=self.dropout_probability, training=True)\n",
    "        # Important when lstm num_layers > 1\n",
    "        output = output[:, -1, :] # take the last decoder cell's outputs\n",
    "        y_pred = self.fc(output)\n",
    "        return y_pred\n",
    "\n",
    "    def init_hidden1(self, batch_size):\n",
    "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
    "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_1))\n",
    "        return hidden_state, cell_state\n",
    "\n",
    "    def init_hidden2(self, batch_size):\n",
    "        hidden_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
    "        cell_state = Variable(torch.zeros(self.stacked_layers, batch_size, self.hidden_size_2))\n",
    "        return hidden_state, cell_state\n",
    "\n",
    "    def loss(self, pred, truth):\n",
    "        return self.loss_fn(pred, truth)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self(torch.tensor(X, dtype=torch.float32)).view(-1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "649bcf61-e0d5-415c-b9ed-a6fb4f6ad7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = scaled_array.shape[-1]\n",
    "sequence_length = 10\n",
    "output_length = 1\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 150\n",
    "learning_rate = 1e-3\n",
    "\n",
    "bayesian_lstm = BayesianLSTM(n_features=n_features,\n",
    "                             output_length=output_length,\n",
    "                             batch_size = batch_size)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(bayesian_lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5adca94e-ad6d-4216-ba8b-5dc06ccba0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 loss:  0.0055957273580133915\n",
      "epoch 20 loss:  0.0028691748157143593\n",
      "epoch 30 loss:  0.002242554444819689\n",
      "epoch 40 loss:  0.0017713351408019662\n",
      "epoch 50 loss:  0.0010617817752063274\n",
      "epoch 60 loss:  0.001049292040988803\n",
      "epoch 70 loss:  0.0008963532745838165\n",
      "epoch 80 loss:  0.00040437618736177683\n",
      "epoch 90 loss:  0.0009107652003876865\n",
      "epoch 100 loss:  0.0004611111944541335\n",
      "epoch 110 loss:  0.0004423115460667759\n",
      "epoch 120 loss:  0.00040046300273388624\n",
      "epoch 130 loss:  0.001349142869003117\n",
      "epoch 140 loss:  0.00037501248880289495\n",
      "epoch 150 loss:  0.0001699277199804783\n"
     ]
    }
   ],
   "source": [
    "bayesian_lstm.train()\n",
    "\n",
    "for e in range(1, n_epochs+1):\n",
    "    for b in range(0, len(X_train), batch_size):\n",
    "        features = X_train[b:b+batch_size,:,:]\n",
    "        target = y_train[b:b+batch_size]\n",
    "\n",
    "        X_batch = torch.tensor(features,dtype=torch.float32)\n",
    "        y_batch = torch.tensor(target,dtype=torch.float32)\n",
    "\n",
    "        output = bayesian_lstm(X_batch)\n",
    "        loss = criterion(output.view(-1), y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if e % 10 == 0:\n",
    "      print('epoch', e, 'loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d32058b-0393-46fd-a112-9f2898c6a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = sequence_length\n",
    "\n",
    "def inverse_transform(y):\n",
    "  return target_scaler.inverse_transform(y.reshape(-1, 1))\n",
    "\n",
    "training_df = pd.DataFrame()\n",
    "training_df['date'] = df['date'].iloc[offset:n_train + offset:1]\n",
    "training_predictions = bayesian_lstm.predict(X_train)\n",
    "training_df['Close'] = inverse_transform(training_predictions)\n",
    "training_df['source'] = 'Training Prediction'\n",
    "\n",
    "training_truth_df = pd.DataFrame()\n",
    "training_truth_df['date'] = training_df['date']\n",
    "training_truth_df['Close'] = df['Close'].iloc[offset:n_train + offset:1]\n",
    "training_truth_df['source'] = 'True Values'\n",
    "\n",
    "testing_df = pd.DataFrame()\n",
    "testing_df['date'] = df['date'].iloc[n_train + offset::1]\n",
    "testing_predictions = bayesian_lstm.predict(X_test)\n",
    "testing_df['Close'] = inverse_transform(testing_predictions)\n",
    "testing_df['source'] = 'Test Prediction'\n",
    "\n",
    "testing_truth_df = pd.DataFrame()\n",
    "testing_truth_df['date'] = testing_df['date']\n",
    "testing_truth_df['Close'] = df['Close'].iloc[n_train + offset::1]\n",
    "testing_truth_df['source'] = 'True Values'\n",
    "\n",
    "evaluation = pd.concat([training_df,\n",
    "                        testing_df,\n",
    "                        training_truth_df,\n",
    "                        testing_truth_df\n",
    "                        ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3ec05c8-1059-4838-bfeb-78ecd298ca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_35.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.line(evaluation,\n",
    "                 x=\"date\",\n",
    "                 y=\"Close\",\n",
    "                 color=\"source\",\n",
    "                 title=\"Copper Price Over Time\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9e0219f-f8a5-4d96-b3c2-e32124f55eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pz/_wgxb2_55vq_03wjlfqtmmm80000gn/T/ipykernel_18954/1463710952.py:8: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/var/folders/pz/_wgxb2_55vq_03wjlfqtmmm80000gn/T/ipykernel_18954/1463710952.py:11: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "/var/folders/pz/_wgxb2_55vq_03wjlfqtmmm80000gn/T/ipykernel_18954/1463710952.py:12: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_experiments = 100\n",
    "\n",
    "test_uncertainty_df = pd.DataFrame()\n",
    "test_uncertainty_df['date'] = testing_df['date']\n",
    "\n",
    "for i in range(n_experiments):\n",
    "  experiment_predictions = bayesian_lstm.predict(X_test)\n",
    "  test_uncertainty_df['Close_{}'.format(i)] = inverse_transform(experiment_predictions)\n",
    "\n",
    "Close_df = test_uncertainty_df.filter(like='Close', axis=1)\n",
    "test_uncertainty_df['Close_mean'] = Close_df.mean(axis=1)\n",
    "test_uncertainty_df['Close_std'] = Close_df.std(axis=1)\n",
    "\n",
    "test_uncertainty_df = test_uncertainty_df[['date', 'Close_mean', 'Close_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a701e3e6-bbc4-4e4d-8f1e-1afb5908265a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_uncertainty_df['lower_bound'] = test_uncertainty_df['Close_mean'] - 3*test_uncertainty_df['Close_std']\n",
    "test_uncertainty_df['upper_bound'] = test_uncertainty_df['Close_mean'] + 3*test_uncertainty_df['Close_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f2c1d26-c1e7-412a-847b-eddf05a2a894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_41.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_uncertainty_plot_df = test_uncertainty_df.copy(deep=True)\n",
    "test_uncertainty_plot_df = test_uncertainty_plot_df\n",
    "truth_uncertainty_plot_df = testing_truth_df.copy(deep=True)\n",
    "truth_uncertainty_plot_df = truth_uncertainty_plot_df\n",
    "\n",
    "upper_trace = go.Scatter(\n",
    "    x=test_uncertainty_plot_df['date'],\n",
    "    y=test_uncertainty_plot_df['upper_bound'],\n",
    "    mode='lines',\n",
    "    fill=None,\n",
    "    name='99% Upper Confidence Bound'\n",
    "    )\n",
    "lower_trace = go.Scatter(\n",
    "    x=test_uncertainty_plot_df['date'],\n",
    "    y=test_uncertainty_plot_df['lower_bound'],\n",
    "    mode='lines',\n",
    "    fill='tonexty',\n",
    "    fillcolor='rgba(255, 211, 0, 0.1)',\n",
    "    name='99% Lower Confidence Bound'\n",
    "    )\n",
    "real_trace = go.Scatter(\n",
    "    x=truth_uncertainty_plot_df['date'],\n",
    "    y=truth_uncertainty_plot_df['Close'],\n",
    "    mode='lines',\n",
    "    fill=None,\n",
    "    name='Real Values'\n",
    "    )\n",
    "\n",
    "data = [upper_trace, lower_trace, real_trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "fig.update_layout(title='Uncertainty Quantification for Copper Price Test Data',\n",
    "                   xaxis_title='Year',\n",
    "                   yaxis_title='Price (USD)')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9955d7ff-5c47-4230-b598-5a267bb18aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of points contained within 99% confidence interval: 0.950625\n"
     ]
    }
   ],
   "source": [
    "bounds_df = pd.DataFrame()\n",
    "\n",
    "# Using 99% confidence bounds\n",
    "bounds_df['lower_bound'] = test_uncertainty_plot_df['lower_bound']\n",
    "bounds_df['prediction'] = test_uncertainty_plot_df['Close_mean']\n",
    "bounds_df['real_value'] = truth_uncertainty_plot_df['Close']\n",
    "bounds_df['upper_bound'] = test_uncertainty_plot_df['upper_bound']\n",
    "\n",
    "bounds_df['contained'] = ((bounds_df['real_value'] >= bounds_df['lower_bound']) &\n",
    "                          (bounds_df['real_value'] <= bounds_df['upper_bound']))\n",
    "\n",
    "print(\"Proportion of points contained within 99% confidence interval:\",\n",
    "      bounds_df['contained'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
